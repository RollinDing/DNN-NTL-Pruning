{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.0.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ruyi/anaconda3/envs/pytorch/lib/python3.9/site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: filelock in /home/ruyi/anaconda3/envs/pytorch/lib/python3.9/site-packages (from gdown) (3.12.4)\n",
      "Requirement already satisfied: requests[socks] in /home/ruyi/anaconda3/envs/pytorch/lib/python3.9/site-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /home/ruyi/anaconda3/envs/pytorch/lib/python3.9/site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ruyi/anaconda3/envs/pytorch/lib/python3.9/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ruyi/anaconda3/envs/pytorch/lib/python3.9/site-packages (from requests[socks]->gdown) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ruyi/anaconda3/envs/pytorch/lib/python3.9/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ruyi/anaconda3/envs/pytorch/lib/python3.9/site-packages (from requests[socks]->gdown) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ruyi/anaconda3/envs/pytorch/lib/python3.9/site-packages (from requests[socks]->gdown) (2023.11.17)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/ruyi/anaconda3/envs/pytorch/lib/python3.9/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading gdown-5.0.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-5.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_id_by_model(folder_name):\n",
    "  file_id = {'resnet18_100-epochs_stl10': '14_nH2FkyKbt61cieQDiSbBVNP8-gtwgF',\n",
    "             'resnet18_100-epochs_cifar10': '1lc2aoVtrAetGn0PnTkOyFzPCIucOJq7C',\n",
    "             'resnet50_50-epochs_stl10': '1ByTKAUsdm_X7tLcii6oAEl5qFRqRMZSu'}\n",
    "  return file_id.get(folder_name, \"Model not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18_100-epochs_stl10 14_nH2FkyKbt61cieQDiSbBVNP8-gtwgF\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'resnet18_100-epochs_stl10'\n",
    "file_id = get_file_id_by_model(folder_name)\n",
    "print(folder_name, file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=14_nH2FkyKbt61cieQDiSbBVNP8-gtwgF\n",
      "From (redirected): https://drive.google.com/uc?id=14_nH2FkyKbt61cieQDiSbBVNP8-gtwgF&confirm=t&uuid=2ce8dccc-6dc2-402e-9428-06179075ef31\n",
      "To: /mnt/2tb/ruyi/DNN-NTL-Pruning/src/ssl/resnet18_100-epochs_stl10.zip\n",
      "100%|██████████| 116M/116M [00:01<00:00, 92.3MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  resnet18_100-epochs_stl10.zip\n",
      "  inflating: checkpoint_0100.pth.tar  \n",
      "  inflating: config.yml              \n",
      "  inflating: events.out.tfevents.1610901470.4cb2c837708d.2683858.0  \n",
      "  inflating: training.log            \n",
      "checkpoint_0100.pth.tar\n",
      "config.yml\n",
      "events.out.tfevents.1610901470.4cb2c837708d.2683858.0\n",
      "prune-ssl-model.py\n",
      "resnet18_100-epochs_stl10.zip\n",
      "simclr.ipynb\n",
      "training.log\n"
     ]
    }
   ],
   "source": [
    "# download and extract model files\n",
    "os.system('gdown https://drive.google.com/uc?id={}'.format(file_id))\n",
    "os.system('unzip {}'.format(folder_name))\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stl10_data_loaders(download, batch_size=256):\n",
    "  train_dataset = datasets.STL10('../../data', split='train', download=download,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "  train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                            num_workers=10, drop_last=False, shuffle=True)\n",
    "  \n",
    "  test_dataset = datasets.STL10('../../data', split='test', download=download,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "  test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
    "                            num_workers=10, drop_last=False, shuffle=False)\n",
    "  return train_loader, test_loader\n",
    "\n",
    "def get_cifar10_data_loaders(download, shuffle=False, batch_size=256):\n",
    "  train_dataset = datasets.CIFAR10('../../data', train=True, download=download,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "  train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                            num_workers=10, drop_last=False, shuffle=True)\n",
    "  \n",
    "  test_dataset = datasets.CIFAR10('../../data', train=False, download=download,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "  test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
    "                            num_workers=10, drop_last=False, shuffle=False)\n",
    "  return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruyi/anaconda3/envs/pytorch/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ruyi/anaconda3/envs/pytorch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet50(pretrained=False, num_classes=10).to(device)\n",
    "checkpoint = torch.load('../../base_models/checkpoint_0040.pth.tar', map_location=device)\n",
    "state_dict = checkpoint['state_dict']\n",
    "\n",
    "for k in list(state_dict.keys()):\n",
    "\n",
    "  if k.startswith('backbone.'):\n",
    "    if k.startswith('backbone') and not k.startswith('backbone.fc'):\n",
    "      # remove prefix\n",
    "      state_dict[k[len(\"backbone.\"):]] = state_dict[k]\n",
    "  del state_dict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "log = model.load_state_dict(state_dict, strict=False)\n",
    "assert log.missing_keys == ['fc.weight', 'fc.bias']\n",
    "train_loader, test_loader = get_stl10_data_loaders(download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=0.0008)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\tTop1 Train accuracy 49.05445861816406\tTop1 Test accuracy: 63.4326171875\tTop5 Train accuracy: 96.77978515625\t\n",
      "Epoch 1\tTop1 Train accuracy 68.87867736816406\tTop1 Test accuracy: 68.61328125\tTop5 Train accuracy: 98.0517578125\t\n",
      "Epoch 2\tTop1 Train accuracy 79.34972381591797\tTop1 Test accuracy: 71.88720703125\tTop5 Train accuracy: 98.45458984375\t\n",
      "Epoch 3\tTop1 Train accuracy 86.81526184082031\tTop1 Test accuracy: 71.3720703125\tTop5 Train accuracy: 98.33251953125\t\n",
      "Epoch 4\tTop1 Train accuracy 92.85271453857422\tTop1 Test accuracy: 71.40380859375\tTop5 Train accuracy: 98.44970703125\t\n",
      "Epoch 5\tTop1 Train accuracy 96.91291809082031\tTop1 Test accuracy: 72.32666015625\tTop5 Train accuracy: 98.4326171875\t\n",
      "Epoch 6\tTop1 Train accuracy 98.42485809326172\tTop1 Test accuracy: 72.1337890625\tTop5 Train accuracy: 98.59130859375\t\n",
      "Epoch 7\tTop1 Train accuracy 98.72013092041016\tTop1 Test accuracy: 71.62353515625\tTop5 Train accuracy: 98.27392578125\t\n",
      "Epoch 8\tTop1 Train accuracy 98.58341217041016\tTop1 Test accuracy: 70.9375\tTop5 Train accuracy: 98.14208984375\t\n",
      "Epoch 9\tTop1 Train accuracy 98.00436401367188\tTop1 Test accuracy: 70.7861328125\tTop5 Train accuracy: 98.06640625\t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m   top1_train_accuracy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m top1[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m   optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m   \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m   optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m top1_train_accuracy \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m (counter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "  top1_train_accuracy = 0\n",
    "  for counter, (x_batch, y_batch) in enumerate(train_loader):\n",
    "    x_batch = x_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "\n",
    "    logits = model(x_batch)\n",
    "    loss = criterion(logits, y_batch)\n",
    "    \n",
    "    top1 = accuracy(logits, y_batch, topk=(1,))\n",
    "    top1_train_accuracy += top1[0]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  top1_train_accuracy /= (counter + 1)\n",
    "  top1_accuracy = 0\n",
    "  top5_accuracy = 0\n",
    "  for counter, (x_batch, y_batch) in enumerate(test_loader):\n",
    "    x_batch = x_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "\n",
    "    logits = model(x_batch)\n",
    "  \n",
    "    top1, top5 = accuracy(logits, y_batch, topk=(1,5))\n",
    "    top1_accuracy += top1[0]\n",
    "    top5_accuracy += top5[0]\n",
    "  \n",
    "  top1_accuracy /= (counter + 1)\n",
    "  top5_accuracy /= (counter + 1)\n",
    "  print(f\"Epoch {epoch}\\tTop1 Train accuracy {top1_train_accuracy.item()}\\tTop1 Test accuracy: {top1_accuracy.item()}\\tTop5 Train accuracy: {top5_accuracy.item()}\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
